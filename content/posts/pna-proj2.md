+++
title = "PNA - Project 2"
weight = 1
order = 1
date = 2020-01-26
#insert_anchor_links = "right"

[taxonomies]
tags = ["notes", "rust"]
+++

## LFS

### LFS paper
- 空闲分区管理的一些`fact`
  - 磁盘划分为固定大小的段
  - 每段从头到尾按序写入
  - 每段中有用数据必须先被安置后才允许被覆盖
  - 日志的调度单位是段
    - `thread`这里还不知道怎么翻译最合适
  - 段足够大到能够冲淡寻倒带来的开销
    - `512K/1M`
- 段清理机制
  - 定义：从段中移走“活数据”的过程
  - 过程
    - 读取几个要清理的段
    - 找到活数据
    - 将活数据写回空闲段
  - 问题
    - 确定段中哪些块中是活数据
    - 这些块都属于哪些文件段
  - 解决
    - 每段中有段描述块
      - meta-data of a segment
    - 用来标记信息
      - 有点像reversed index
      - 每个文件数据块所属文件号码
      - 每个文件数据块是对应文件的第几块
    - 每段中可以有多个段描述块
      - 缓冲中的脏块少了，写入时占不满一个段
    - 用来分辨活数据和可以被覆盖的块
      - 查看某个块所属文件的inode/indirect block是否还指向该文件
      - 优化：
        - inode map entry中使用版本号，文件被删除或者0填充时+1
        - inode号+版本号=>uid
        - uid唯一标识了文件内容
        - 段描述块中记录段中每一个块的uid
        - 逆向检查文件是否是活的只需比较uid和inode map entry中的版本号
        - 不用真的去查inode/indirect block
        - 也就不需要位图或者空闲链这些鬼玩意来记录空闲空间了
          - 不占用额外内外存空间
          - 不用关心这些东西的一致性
  - 虽然段描述块有额外开销但是可以在恢复和清理时带来收益
    - worthy tradeoff
- 清理策略的选择
  - 问题
    - 时间（待解决）
      - 后台daemon
      - 只在低峰期
      - 空间不多时
    - 范围（待解决）
      - 清理=>reorganize data
      - 每次清理的范围大，数据被整理的几率越高
    - 该清理的段应有什么特征
      - 越碎片化越好？
        - 应该不是，频繁访问的小文件会造成这种段的产生
    - 被清理之后的数据该如何组织
      - 尝试增强读取时的局部性
      - 按时间戳排序age sort
  - 解决
    - 控制空闲段数在一个区间内
      - 但具体数值对性能的影响不明显
    - 段特征和数据组织更关键
    - 用write cost来量化
      - 含义：每写入一字节新数据的磁盘平均忙时
        - 包括了清理花费
      - 表示：实际花费的时间÷理想情况下花费时间
        - 理想情况：假如没有清理花费、寻道时间、旋转延时情况下
        - 1.0是完美情况
        - 10代表磁盘带宽的十分之一被用来写入新数据
    - 近似算法
      - 贪心
      - 对于LFS，即近似按序写入
        - 寻道时间、旋转演示可以忽略
        - $write\ cost = \frac{total\ bytes\ r/w}{new\ bytes\ w} = \frac{2}{1-u}$
        - $u$是清理时读出数据中活数据比值
      - 上为保守估算
        - 读出数据时不一定要读出整段
        - 可以只读出（描述块+）活数据
  - 评价
    - $u<0.5$时性能比FFS改进后更强
      - $u$只是局部特性
        - 注意只代表读出数据中活数据比值
        - 也就是说整块磁盘的占用率往往比$u$大
    - 清理时可以尽量选$u$小的段
    - tradeoff：磁盘利用率 vs 性能
    - 较理想使用场景
      - 大部分的段几乎全满=>高效存储数据
      - 少部分的块几乎为空=>高效空间清理
      - 低价&高效
  - pitfalls
    - 局部性的上升反而带来性能的下降？
      - 较少访问的段中空闲空间更“值钱”
        - 因为较少被访问的段更难变得碎片化/更少被清理
        - 被困在其中的空闲空间更难被释放/再利用
        - 导致更多的段$u$刚好超过阀值
        - 从而更难被清理
      - 较常访问的段中数据会更快失效
        - 更容易掉到阀值以下
        - 从而更易被清理
  - 改进
    - 用**性价比**来评价而不是简单的write cost
    - $\frac{benifit}{cost}=\frac{free\ space\ generated \times age\ of\ data}{cost}=\frac{(1-u)\times age}{1+u}$
    - benifit
      - 清理可以产生的空间
      - 这些空间可以维持的时间
        - 用段中最小的块年龄来估计
    - cost
      - 读+写
  - 段用量表
    - 为了支持上面的性价比清理策略
    - 区分冷热段
      - 冷段$u=0.75$时清理
      - 热段$u=0.15$时清理
    - 记录
      - 每段的活数据数量
      - 每块的最近修改时间
    - 写入/修改时设置
    - 存在log里面
    - 地址存在检查点区域
- 恢复
  - 检查点的创建
    - 先向日志中写入所有修改过的信息
    - 再在磁盘固定位置写入检查点
    - 实际上有两个检查点区域
    - 为了防止在创建检查点时崩溃
    - 两个交替写入
  - 重启时读取检查点初始化数据结构
    - 使用最新的一个检查点
  - 间歇性执行或在磁盘卸载/关机时检查点创建操作
- roll-forward/redo
  